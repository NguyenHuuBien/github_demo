# -*- coding: utf-8 -*-
"""LinearRegression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JpRozq7-47Evr9ZBfJ7G1O2xK7EWL1mM
"""

import pandas as pd
# Import the dataset.
training_df = pd.read_csv(filepath_or_buffer="https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv")

training_df.head()

import csv
from math import sqrt

from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler

with open('california_housing_train.csv', newline='') as f:
    reader = csv.reader(f)
    data = list(reader)
    # print(type(data))


# print(data)

dataset = data
for row in range(len(dataset)):
    for col in range(len(dataset[row])):
        dataset[row][col] = float(dataset[row][col])

def dataset_minmax(dataset):
    minmax = list()
    for i in range(len(dataset[0])):
        col_values = [row[i] for row in dataset]
        value_min = min(col_values)
        value_max = max(col_values)
        minmax.append([value_min, value_max])
    return minmax

minmax = dataset_minmax(dataset)

def normalize_dataset(dataset, minmax):
    for row in dataset:
        for i in range(len(row)):
            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])
normalize_dataset(data, minmax)

def column_means(dataset):
    means = [0 for i in range(len(dataset[0]))]
    for i in range(len(dataset[0])):
        col_values = [row[i] for row in dataset]
        means[i] = sum(col_values) / float(len(dataset))
    return means
means = column_means(dataset)

def column_stdevs(dataset, means):
    stdevs = [0 for i in range(len(dataset[0]))]
    for i in range(len(dataset[0])):
        variance = [pow(row[i]-means[i], 2) for row in dataset]
        stdevs[i] = sum(variance)
    stdevs = [sqrt(x/(float(len(dataset)-1))) for x in stdevs]
    return stdevs
stdevs = column_stdevs(dataset, means)

def standardize_dataset(dataset, means, stdevs):
    for row in dataset:
        for i in range(len(row)):
            row[i] = (row[i] - means[i]) / stdevs[i]
standardize_dataset(dataset, means, stdevs)

scaler = MinMaxScaler()
# transform data

scaled = scaler.fit_transform(dataset)
print(scaled)

from numpy import array
from numpy import argmax
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
# define example
data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']
values = array(data)
print(values)
# integer encode
# label_encoder = LabelEncoder()
# integer_encoded = label_encoder.fit_transform(values)
# print(integer_encoded)

from google.colab import drive
drive.mount('/content/drive')

"""# Mục mới"""

